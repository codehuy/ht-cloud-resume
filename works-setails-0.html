<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cloud Resume Challenge</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>AWS Cloud Resume Challenge</h1>
    </header>

    <section>
        <h2>Introduction</h2>
        <p>If you're like me, you learn best by doing. The AWS Cloud Resume Challenge was an awesome way to learn about AWS since I had no prior experience. This project involved designing and developing my resume website using AWS services.</p>
    </section>

    <section>
        <h2>Website Design & Development</h2>
        <p>For this project, I used HTML, JavaScript, and CSS to craft a visually appealing and interactive resume. I opted for a template from <a href="http://designstub.com" target="_blank">designstub.com</a> since I didn't have much expertise in web development.</p>
        <p>Quick tip: download the "Live Server" extension inside VS Code to easily help update/troubleshoot the website locally with live reloads for HTML and CSS changes.</p>
    </section>

    <section>
        <h2>Leveraging AWS Services</h2>
        <p>I utilized various AWS services to bring the website to life, including:</p>
        <ul>
            <li>S3</li>
            <li>Route 53</li>
            <li>CloudFront</li>
            <li>DynamoDB</li>
            <li>Lambda</li>
        </ul>
        <p>Additionally, I used GitHub Actions for CI/CD, OpenID Connect for secure authentication, and multi-factor authentication (MFA) for enhanced security.</p>
    </section>

    <section>
        <h2>Amazon S3</h2>
        <p>Amazon S3 was the foundation for hosting my resume website. I uploaded the HTML, JavaScript, and CSS files to an S3 bucket, making them accessible over the internet.</p>
        <h3>CI/CD Deployment with GitHub Actions</h3>
        <p>GitHub Actions was set up to handle continuous integration and deployment, allowing changes pushed to the repository to automatically trigger updates to the S3 bucket.</p>
        <pre>
            <code>
name: S3 Website
on:
  workflow_dispatch:
  push:
    branches:
    - main

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@master
    - uses: jakejarvis/s3-sync-action@master
      with:
        args: --acl private --follow-symlinks --delete
      env:
        AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION: 'us-east-1'
        SOURCE_DIR: 'website'
            </code>
        </pre>
        <p>This process streamlined updates, and later I secured it further using OpenID Connect to avoid hardcoding AWS keys.</p>
    </section>

    <section>
        <h2>Route 53</h2>
        <p>Amazon Route 53 was used to register a domain name for my website. I secured my full name for the domain and connected it to the website hosted on S3.</p>
    </section>

    <section>
        <h2>CloudFront</h2>
        <p>CloudFront was set up to improve performance and security. It cached my website's content at edge locations, ensuring fast and reliable access for users worldwide.</p>
    </section>

    <section>
        <h2>DynamoDB</h2>
        <p>I integrated Amazon DynamoDB to add dynamic content like a visitor count. This required a table called 'resume-views' and a Lambda function to increment the views.</p>
    </section>

    <section>
        <h2>Lambda Function</h2>
        <p>AWS Lambda was used to handle the backend logic for interacting with DynamoDB:</p>
        <pre>
            <code>
import json
import boto3
dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table('resume-views')

def lambda_handler(event, context):
    response = table.get_item(Key={'id': '1'})
    views = response['Item']['views']
    views += 1
    table.put_item(Item={'id': '1', 'views': views})
    return views
            </code>
        </pre>
        <p>On the frontend, a JavaScript function connects with the Lambda function via its URL to update the view count on the webpage.</p>
    </section>

    <section>
        <h2>Conclusion</h2>
        <p>The AWS Cloud Resume Challenge was an excellent opportunity to learn about cloud computing and web development. By leveraging AWS services and following best practices, I successfully built and deployed a dynamic resume website.</p>
    </section>
</body>
</html>
